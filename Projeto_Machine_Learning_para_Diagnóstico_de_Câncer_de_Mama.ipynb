{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projeto Machine Learning para Diagnóstico de Câncer de Mama.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jussara-S-Silva/Machine-Learning/blob/main/Projeto_Machine_Learning_para_Diagn%C3%B3stico_de_C%C3%A2ncer_de_Mama.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_uJn-uQZlK7"
      },
      "source": [
        "# Machine Learning para Diagnóstico de Câncer de Mama\n",
        "\n",
        "Este projeto tem como finalidade apresentar os conhecimentos que adqueri através das aulas e artigos do Professor Carlos Melo pelo Blog Sigmoidal\n",
        "\n",
        "* **[Link para o blog Sigmoidal](https://sigmoidal.ai/)**\n",
        "\n",
        "Neste projeto usaremos a linguagem Python, bibliotecas e dataframes para desenvolver um projeto de *Machine Learning* que irá analisar os dados e atribuir o diagnóstico de M - Maligno ou B - Benigno.\n",
        "\n",
        "*Data Science* está sendo muito utilizada na medicina, inclusive para a detecção do câncer de mama vem crescendo cada vez mais, e contribuído para diagnósticos mais rápidos e precisos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3yD447plfoy"
      },
      "source": [
        "## Importar os Dados\n",
        "\n",
        "Na construção deste modelo de *Machine Learning* foi usado o banco de dados Wisconsin, disponibilizado no [Repositório de Machine Learning da UCI](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7Yfo6Xslv1M"
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "\n",
        "sns.set_style()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fD95uTPl8mw"
      },
      "source": [
        "# Dataset em csv \n",
        "data_path = \"https://www.dropbox.com/s/z8nw6pfumdw3bb9/breast-cancer-wisconsin.csv?raw=1\" \n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "# Excluir coluna com erro\n",
        "df.drop('Unnamed: 32', axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmWnFAV9xcYu"
      },
      "source": [
        "## Análise Exploratória\n",
        "\n",
        "Iremos examinar as dimensões do DataFrame e as primeiras entradas. Isso possibilitará criar uma consciência situacional sobre o formato de entrada e da estrutura geral dos dados.\n",
        "\n",
        "* A coluna `id` representa o valor de identificação.\n",
        "* A coluna `diagnosis` é a variável em questão.\n",
        "  * **M -** *Maligno*\n",
        "  * **B -** *Benigno*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJD1uRUzxjrU",
        "outputId": "df86ce9c-0cc1-4b53-d266-24b8fe3f96bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# dimensões do df\n",
        "print(\"DIMENSÕES DO DATAFRAME:\")\n",
        "print(\"Linhas:\\t\\t{}\".format(df.shape[0]))\n",
        "print(\"Colunas:\\t{}\".format(df.shape[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DIMENSÕES DO DATAFRAME:\n",
            "Linhas:\t\t569\n",
            "Colunas:\t32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B59GBVIdxsUK"
      },
      "source": [
        "Vejamos as 5 primeiras entradas para visualizar inicialmente sobre o tipo de formato e criar hipóteses iniciais do processo investigativo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zfOZFI0xtu6",
        "outputId": "0978963c-2c67-4d19-bc59-64b4637a8bf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "# ver as 5 primeiras entradas\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id diagnosis  ...  symmetry_worst  fractal_dimension_worst\n",
              "0    842302         M  ...          0.4601                  0.11890\n",
              "1    842517         M  ...          0.2750                  0.08902\n",
              "2  84300903         M  ...          0.3613                  0.08758\n",
              "3  84348301         M  ...          0.6638                  0.17300\n",
              "4  84358402         M  ...          0.2364                  0.07678\n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruN79pMhx5Cs"
      },
      "source": [
        "Através do Describe veremos resumo estatístico das variáveis numéricas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAyqxTw0mBXY",
        "outputId": "a86852f1-9dba-47c8-9986-f3a7e6727585",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.037183e+07</td>\n",
              "      <td>14.127292</td>\n",
              "      <td>19.289649</td>\n",
              "      <td>91.969033</td>\n",
              "      <td>654.889104</td>\n",
              "      <td>0.096360</td>\n",
              "      <td>0.104341</td>\n",
              "      <td>0.088799</td>\n",
              "      <td>0.048919</td>\n",
              "      <td>0.181162</td>\n",
              "      <td>0.062798</td>\n",
              "      <td>0.405172</td>\n",
              "      <td>1.216853</td>\n",
              "      <td>2.866059</td>\n",
              "      <td>40.337079</td>\n",
              "      <td>0.007041</td>\n",
              "      <td>0.025478</td>\n",
              "      <td>0.031894</td>\n",
              "      <td>0.011796</td>\n",
              "      <td>0.020542</td>\n",
              "      <td>0.003795</td>\n",
              "      <td>16.269190</td>\n",
              "      <td>25.677223</td>\n",
              "      <td>107.261213</td>\n",
              "      <td>880.583128</td>\n",
              "      <td>0.132369</td>\n",
              "      <td>0.254265</td>\n",
              "      <td>0.272188</td>\n",
              "      <td>0.114606</td>\n",
              "      <td>0.290076</td>\n",
              "      <td>0.083946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.250206e+08</td>\n",
              "      <td>3.524049</td>\n",
              "      <td>4.301036</td>\n",
              "      <td>24.298981</td>\n",
              "      <td>351.914129</td>\n",
              "      <td>0.014064</td>\n",
              "      <td>0.052813</td>\n",
              "      <td>0.079720</td>\n",
              "      <td>0.038803</td>\n",
              "      <td>0.027414</td>\n",
              "      <td>0.007060</td>\n",
              "      <td>0.277313</td>\n",
              "      <td>0.551648</td>\n",
              "      <td>2.021855</td>\n",
              "      <td>45.491006</td>\n",
              "      <td>0.003003</td>\n",
              "      <td>0.017908</td>\n",
              "      <td>0.030186</td>\n",
              "      <td>0.006170</td>\n",
              "      <td>0.008266</td>\n",
              "      <td>0.002646</td>\n",
              "      <td>4.833242</td>\n",
              "      <td>6.146258</td>\n",
              "      <td>33.602542</td>\n",
              "      <td>569.356993</td>\n",
              "      <td>0.022832</td>\n",
              "      <td>0.157336</td>\n",
              "      <td>0.208624</td>\n",
              "      <td>0.065732</td>\n",
              "      <td>0.061867</td>\n",
              "      <td>0.018061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>8.670000e+03</td>\n",
              "      <td>6.981000</td>\n",
              "      <td>9.710000</td>\n",
              "      <td>43.790000</td>\n",
              "      <td>143.500000</td>\n",
              "      <td>0.052630</td>\n",
              "      <td>0.019380</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106000</td>\n",
              "      <td>0.049960</td>\n",
              "      <td>0.111500</td>\n",
              "      <td>0.360200</td>\n",
              "      <td>0.757000</td>\n",
              "      <td>6.802000</td>\n",
              "      <td>0.001713</td>\n",
              "      <td>0.002252</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007882</td>\n",
              "      <td>0.000895</td>\n",
              "      <td>7.930000</td>\n",
              "      <td>12.020000</td>\n",
              "      <td>50.410000</td>\n",
              "      <td>185.200000</td>\n",
              "      <td>0.071170</td>\n",
              "      <td>0.027290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.055040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8.692180e+05</td>\n",
              "      <td>11.700000</td>\n",
              "      <td>16.170000</td>\n",
              "      <td>75.170000</td>\n",
              "      <td>420.300000</td>\n",
              "      <td>0.086370</td>\n",
              "      <td>0.064920</td>\n",
              "      <td>0.029560</td>\n",
              "      <td>0.020310</td>\n",
              "      <td>0.161900</td>\n",
              "      <td>0.057700</td>\n",
              "      <td>0.232400</td>\n",
              "      <td>0.833900</td>\n",
              "      <td>1.606000</td>\n",
              "      <td>17.850000</td>\n",
              "      <td>0.005169</td>\n",
              "      <td>0.013080</td>\n",
              "      <td>0.015090</td>\n",
              "      <td>0.007638</td>\n",
              "      <td>0.015160</td>\n",
              "      <td>0.002248</td>\n",
              "      <td>13.010000</td>\n",
              "      <td>21.080000</td>\n",
              "      <td>84.110000</td>\n",
              "      <td>515.300000</td>\n",
              "      <td>0.116600</td>\n",
              "      <td>0.147200</td>\n",
              "      <td>0.114500</td>\n",
              "      <td>0.064930</td>\n",
              "      <td>0.250400</td>\n",
              "      <td>0.071460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>9.060240e+05</td>\n",
              "      <td>13.370000</td>\n",
              "      <td>18.840000</td>\n",
              "      <td>86.240000</td>\n",
              "      <td>551.100000</td>\n",
              "      <td>0.095870</td>\n",
              "      <td>0.092630</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.033500</td>\n",
              "      <td>0.179200</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.324200</td>\n",
              "      <td>1.108000</td>\n",
              "      <td>2.287000</td>\n",
              "      <td>24.530000</td>\n",
              "      <td>0.006380</td>\n",
              "      <td>0.020450</td>\n",
              "      <td>0.025890</td>\n",
              "      <td>0.010930</td>\n",
              "      <td>0.018730</td>\n",
              "      <td>0.003187</td>\n",
              "      <td>14.970000</td>\n",
              "      <td>25.410000</td>\n",
              "      <td>97.660000</td>\n",
              "      <td>686.500000</td>\n",
              "      <td>0.131300</td>\n",
              "      <td>0.211900</td>\n",
              "      <td>0.226700</td>\n",
              "      <td>0.099930</td>\n",
              "      <td>0.282200</td>\n",
              "      <td>0.080040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8.813129e+06</td>\n",
              "      <td>15.780000</td>\n",
              "      <td>21.800000</td>\n",
              "      <td>104.100000</td>\n",
              "      <td>782.700000</td>\n",
              "      <td>0.105300</td>\n",
              "      <td>0.130400</td>\n",
              "      <td>0.130700</td>\n",
              "      <td>0.074000</td>\n",
              "      <td>0.195700</td>\n",
              "      <td>0.066120</td>\n",
              "      <td>0.478900</td>\n",
              "      <td>1.474000</td>\n",
              "      <td>3.357000</td>\n",
              "      <td>45.190000</td>\n",
              "      <td>0.008146</td>\n",
              "      <td>0.032450</td>\n",
              "      <td>0.042050</td>\n",
              "      <td>0.014710</td>\n",
              "      <td>0.023480</td>\n",
              "      <td>0.004558</td>\n",
              "      <td>18.790000</td>\n",
              "      <td>29.720000</td>\n",
              "      <td>125.400000</td>\n",
              "      <td>1084.000000</td>\n",
              "      <td>0.146000</td>\n",
              "      <td>0.339100</td>\n",
              "      <td>0.382900</td>\n",
              "      <td>0.161400</td>\n",
              "      <td>0.317900</td>\n",
              "      <td>0.092080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.113205e+08</td>\n",
              "      <td>28.110000</td>\n",
              "      <td>39.280000</td>\n",
              "      <td>188.500000</td>\n",
              "      <td>2501.000000</td>\n",
              "      <td>0.163400</td>\n",
              "      <td>0.345400</td>\n",
              "      <td>0.426800</td>\n",
              "      <td>0.201200</td>\n",
              "      <td>0.304000</td>\n",
              "      <td>0.097440</td>\n",
              "      <td>2.873000</td>\n",
              "      <td>4.885000</td>\n",
              "      <td>21.980000</td>\n",
              "      <td>542.200000</td>\n",
              "      <td>0.031130</td>\n",
              "      <td>0.135400</td>\n",
              "      <td>0.396000</td>\n",
              "      <td>0.052790</td>\n",
              "      <td>0.078950</td>\n",
              "      <td>0.029840</td>\n",
              "      <td>36.040000</td>\n",
              "      <td>49.540000</td>\n",
              "      <td>251.200000</td>\n",
              "      <td>4254.000000</td>\n",
              "      <td>0.222600</td>\n",
              "      <td>1.058000</td>\n",
              "      <td>1.252000</td>\n",
              "      <td>0.291000</td>\n",
              "      <td>0.663800</td>\n",
              "      <td>0.207500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  radius_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "count  5.690000e+02   569.000000  ...      569.000000               569.000000\n",
              "mean   3.037183e+07    14.127292  ...        0.290076                 0.083946\n",
              "std    1.250206e+08     3.524049  ...        0.061867                 0.018061\n",
              "min    8.670000e+03     6.981000  ...        0.156500                 0.055040\n",
              "25%    8.692180e+05    11.700000  ...        0.250400                 0.071460\n",
              "50%    9.060240e+05    13.370000  ...        0.282200                 0.080040\n",
              "75%    8.813129e+06    15.780000  ...        0.317900                 0.092080\n",
              "max    9.113205e+08    28.110000  ...        0.663800                 0.207500\n",
              "\n",
              "[8 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLyJr4sH_5B1"
      },
      "source": [
        "Mesmo todos os valores sendo numéricos, particularmente eu gosto de verificar a quantidade de valores únicos para cada *feature*, pois isso permite verificar se os números podem estar representando classes, por exemplo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03UyshwIv8_j",
        "outputId": "e9159c86-38e1-43a1-8d79-412380c2853f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "\n",
        "print(\"\\nVALORES ÚNICOS:\")\n",
        "print(df.nunique().sort_values())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "VALORES ÚNICOS:\n",
            "diagnosis                    2\n",
            "smoothness_worst           411\n",
            "symmetry_mean              432\n",
            "radius_mean                456\n",
            "radius_worst               457\n",
            "smoothness_mean            474\n",
            "texture_mean               479\n",
            "concave points_worst       492\n",
            "symmetry_se                498\n",
            "fractal_dimension_mean     499\n",
            "symmetry_worst             500\n",
            "concave points_se          507\n",
            "texture_worst              511\n",
            "perimeter_worst            514\n",
            "texture_se                 519\n",
            "perimeter_mean             522\n",
            "area_se                    528\n",
            "compactness_worst          529\n",
            "perimeter_se               533\n",
            "concavity_se               533\n",
            "fractal_dimension_worst    535\n",
            "concavity_mean             537\n",
            "compactness_mean           537\n",
            "concavity_worst            539\n",
            "area_mean                  539\n",
            "radius_se                  540\n",
            "compactness_se             541\n",
            "concave points_mean        542\n",
            "area_worst                 544\n",
            "fractal_dimension_se       545\n",
            "smoothness_se              547\n",
            "id                         569\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MViHBQbZw-wp"
      },
      "source": [
        "O *dataset* apresenta a porcentagem de valores da variável em questão, que tem mais valores Benignos do que Malignos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1YC709QAXF1",
        "outputId": "f7709fe1-f1c1-483d-e41b-a6c4950f167e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "# ver porcentagem dos diagnósticos\n",
        "print(\"Diagnósticos:\")\n",
        "print(df.diagnosis.value_counts() / df.shape[0])\n",
        "\n",
        "# plotar o gráfico de barras com os diagnósticos\n",
        "fig, ax = plt.subplots()\n",
        "sns.countplot('diagnosis', data=df, ax=ax)\n",
        "ax.set_title(\"Diagnósticos\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Diagnósticos:\n",
            "B    0.627417\n",
            "M    0.372583\n",
            "Name: diagnosis, dtype: float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEySiTKmGihk"
      },
      "source": [
        "## Preparação dos dados\n",
        "\n",
        "Como parte do pré-processamento dos dados, que irão alimentar o modelo de *Machine Learning*, vou usar o `StardardScaler`, que vem junto com `sklearn.preprocessing`, para padronizar nossos dados numéricos.\n",
        "\n",
        "A nossa variável alvo é categórica, onde *M* representa os tumores malignos e *B* os benignos. Usando `LabelEncoder` com a finalidade de converter variáveis categóricas em numéricas e alimentar o modelo adequadamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgGGE3-yJIPI"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# separar as variáveis independentes da variável alvo\n",
        "X = df.drop(['diagnosis', 'id'], axis=1)\n",
        "y = df['diagnosis']\n",
        "\n",
        "# padronizar as colunas numéricas\n",
        "X = StandardScaler().fit_transform(X)\n",
        "\n",
        "# label encoder na variável alvo\n",
        "y = LabelEncoder().fit_transform(y)\n",
        "\n",
        "# dividir o dataset entre treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHUzXT3OJb_T"
      },
      "source": [
        "O cálculo utilizar por `StandardScaler` para calcular os *scores* é $z = \\frac{x-u}{s}$, onde $u$ é a média das amostras do conjunto de treino e $s$ é o desvio padrão dessa amostra.\n",
        "\n",
        "Dividimos o *dataset* entre treino e teste usando o `train_test_split`, função que facilitar muito o trabalho, e que se encontra em `sklearn.model_selection`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KebSxoHp98D"
      },
      "source": [
        "## Modelo de Machine Learning para detecção do câncer de mama\n",
        "\n",
        "Este problema de detecção de câncer consiste em classificar corretamente um tumor entre benigno e maligno, ou seja, é necessário que o modelo de *Machine Learning* dê uma classificação ao ser alimentado com diversas variáveis independentes (*features*).\n",
        "\n",
        "Aqui, usarei um modelo do tipo *Random Forest* (Floresta Aleatória) devido à sua flexibilidade e facilidade de uso (uma vez que funciona muito bem mesmo sem o ajuste nos hiperparâmetros)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqBYq6OrqDf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "d17d7f1c-e6dd-4c98-f2b3-56efd6bc1e58"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# instanciando o modelo de Random Forest\n",
        "ml_model = RandomForestClassifier(n_estimators = 10, criterion = 'entropy',\n",
        "                                  random_state = 42)\n",
        "\n",
        "# treinando o modelo \n",
        "ml_model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
              "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
              "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkN89ocNyb9U"
      },
      "source": [
        "## Desempenho do modelo de detecção de câncer de mama\n",
        "\n",
        "Aqui, além da métrica de acurácia também inserimos a função `classification_report` para ver ver o desempenho do modelo sobre as métricas de precisão, *recall*, *f1-score* e *support*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1h20z7a_sYJm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "a0308453-5ee7-47d2-f8be-4677540ece12"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# realizar as previsões no dataset de teste\n",
        "y_pred = ml_model.predict(X_test)\n",
        "\n",
        "# ver acurácia geral\n",
        "print('[Acurácia] Random Forest:', accuracy_score(y_test, y_pred))\n",
        "\n",
        "# imprimir o classification report\n",
        "print('\\n[Classification Report] Random Forest')\n",
        "print( classification_report(y_test, y_pred) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Acurácia] Random Forest: 0.9649122807017544\n",
            "\n",
            "[Classification Report] Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97       111\n",
            "           1       1.00      0.90      0.95        60\n",
            "\n",
            "    accuracy                           0.96       171\n",
            "   macro avg       0.97      0.95      0.96       171\n",
            "weighted avg       0.97      0.96      0.96       171\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-vpMdIA3asj"
      },
      "source": [
        "A matriz de confusão permitirá visualizar a acurácia deste modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4gmoM6Ft98s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "64b1963f-5ec0-47e9-cef9-0047b342aa55"
      },
      "source": [
        "# plotar a matriz de confusão\n",
        "pd.DataFrame(confusion_matrix(y_test, y_pred),\n",
        "             index=['neg', 'pos'], columns=['pred_neg', 'pred_pos'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pred_neg</th>\n",
              "      <th>pred_pos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>neg</th>\n",
              "      <td>111</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pos</th>\n",
              "      <td>6</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     pred_neg  pred_pos\n",
              "neg       111         0\n",
              "pos         6        54"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNXUi8Yp2UFw"
      },
      "source": [
        "Podemos ver que o modelo classificatório Random Forest atingiu uma acurácia superior a 96% e lidou muito bem com ambas classificações."
      ]
    }
  ]
}